# WebScraperApplication - Orquestra√ß√£o Central

## Vis√£o Geral

A classe `WebScraperApplication` √© o cora√ß√£o do sistema Web Scraper AI. Ela atua como orquestrador central, coordenando todos os componentes e gerenciando o ciclo de vida da aplica√ß√£o.

**Localiza√ß√£o**: `src/core/application.py`

## Funcionalidade Principal

### **Responsabilidades**
- üèóÔ∏è **Inicializa√ß√£o**: Configura e inicializa todos os componentes do sistema
- üîÑ **Orquestra√ß√£o**: Coordena intera√ß√µes entre diferentes m√≥dulos
- üìä **Monitoramento**: Fornece status e m√©tricas da aplica√ß√£o
- üõ°Ô∏è **Gerenciamento de Estado**: Mant√©m estado global da aplica√ß√£o
- üîß **Configura√ß√£o**: Gerencia configura√ß√µes do sistema

## Arquitetura da Classe

```python
class WebScraperApplication:
    """
    Classe principal da aplica√ß√£o Web Scraper AI.
    
    Implementa padr√£o Singleton para garantir inst√¢ncia √∫nica.
    Coordena todos os componentes do sistema.
    """
```

### **Singleton Pattern**
```python
_instance = None
_lock = threading.Lock()

def __new__(cls):
    if cls._instance is None:
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
    return cls._instance
```

**Justificativa**: Garante que existe apenas uma inst√¢ncia da aplica√ß√£o, evitando conflitos de estado e recursos.

## M√©todos Principais

### **1. Inicializa√ß√£o**

#### `initialize() -> None`
**Prop√≥sito**: Inicializa todos os componentes da aplica√ß√£o.

**Fluxo de Execu√ß√£o**:
1. Verifica se j√° est√° inicializada
2. Carrega configura√ß√µes do sistema
3. Inicializa logger
4. Configura componentes AI
5. Inicializa sistema de arquivos
6. Carrega configura√ß√µes de sites
7. Cria inst√¢ncia do motor de scraping
8. Marca como inicializada

```python
def initialize(self) -> None:
    if self._initialized:
        return
    
    logger.info("Initializing Web Scraper AI Application...")
    
    # Load configurations
    self._load_system_config()
    
    # Initialize AI components
    self._init_ai_components()
    
    # Initialize file manager
    self.file_manager = FileManager()
    
    # Load site configurations
    self._load_site_configs()
    
    # Initialize scraper engine
    max_workers = self.application_config.get('engine', {}).get('max_workers', 3)
    self.engine = ScraperEngine(max_workers=max_workers)
    
    self._initialized = True
    logger.info("‚úÖ Application initialized successfully!")
```

#### `start() -> None`
**Prop√≥sito**: Inicia os servi√ßos da aplica√ß√£o.

**Funcionalidade**:
- Valida inicializa√ß√£o
- Inicia motor de scraping
- Configura monitoramento
- Marca como executando

### **2. Gerenciamento de Configura√ß√£o**

#### `_load_system_config() -> None`
**Prop√≥sito**: Carrega configura√ß√µes do sistema.

**Configura√ß√µes Carregadas**:
- Configura√ß√µes de AI (OpenAI, navega√ß√£o)
- Configura√ß√µes do motor (workers, timeouts)
- Configura√ß√µes de arquivo (paths, backup)
- Configura√ß√µes de logging

#### `add_site_config(site_config: SiteConfig) -> None`
**Prop√≥sito**: Adiciona nova configura√ß√£o de site.

**Valida√ß√µes**:
- Verifica se configura√ß√£o √© v√°lida
- Evita duplicatas
- Valida URLs e seletores

### **3. Gerenciamento de Tarefas**

#### `create_scraping_task(site_name: str, priority: TaskPriority = TaskPriority.NORMAL) -> ScrapingTask`
**Prop√≥sito**: Cria nova tarefa de scraping.

**Processo**:
1. Valida se site existe nas configura√ß√µes
2. Cria inst√¢ncia de `ScrapingTask`
3. Adiciona √† fila do motor
4. Retorna tarefa criada

**Exemplo de Uso**:
```python
task = app.create_scraping_task('example_site', TaskPriority.HIGH)
logger.info(f"Task created: {task.task_id}")
```

### **4. Monitoramento e Status**

#### `get_application_status() -> Dict[str, Any]`
**Prop√≥sito**: Retorna status completo da aplica√ß√£o.

**Informa√ß√µes Retornadas**:
```python
{
    "initialized": bool,
    "running": bool,
    "site_configs_loaded": int,
    "engine_status": {
        "status": str,
        "active_tasks": int,
        "queue_size": int,
        "completed_tasks": int
    },
    "components": {
        "file_manager": bool,
        "ai_client": bool,
        "navigator": bool,
        "pdf_processor": bool
    }
}
```

#### `health_check() -> Dict[str, Any]`
**Prop√≥sito**: Realiza verifica√ß√£o de sa√∫de de todos os componentes.

**Verifica√ß√µes**:
- Status dos componentes core
- Conectividade AI
- Disponibilidade de recursos
- Estado do sistema de arquivos

#### `get_metrics() -> Dict[str, Any]`
**Prop√≥sito**: Coleta m√©tricas de performance.

**M√©tricas Coletadas**:
```python
{
    "engine": {
        "tasks_completed": int,
        "tasks_failed": int,
        "success_rate": float,
        "average_task_time": float,
        "uptime_seconds": float
    },
    "storage": {
        "total_files": int,
        "total_size": int
    }
}
```

### **5. Manuten√ß√£o e Backup**

#### `cleanup_old_data() -> Dict[str, Any]`
**Prop√≥sito**: Realiza limpeza de dados antigos.

**Opera√ß√µes**:
- Remove arquivos tempor√°rios
- Arquiva dados antigos
- Remove tarefas completadas da mem√≥ria
- Otimiza storage

#### `create_backup(description: str = "") -> Dict[str, Any]`
**Prop√≥sito**: Cria backup do sistema.

**Processo**:
1. Compacta dados importantes
2. Inclui configura√ß√µes
3. Salva metadados do backup
4. Retorna informa√ß√µes do backup

### **6. Finaliza√ß√£o**

#### `stop() -> None`
**Prop√≥sito**: Para a aplica√ß√£o graciosamente.

**Processo**:
1. Para motor de scraping
2. Finaliza tarefas ativas
3. Salva estado atual
4. Limpa recursos
5. Marca como parada

## Componentes Gerenciados

### **1. FileManager**
```python
self.file_manager = FileManager()
```
**Responsabilidade**: Gerenciamento de arquivos, backup e organiza√ß√£o.

### **2. ScraperEngine**
```python
self.engine = ScraperEngine(max_workers=max_workers)
```
**Responsabilidade**: Execu√ß√£o multi-threaded de tarefas de scraping.

### **3. AI Components**
```python
self.ai_client = OpenAIClient()
self.navigator = NavigatorAgent(self.ai_client)
self.pdf_processor = PDFProcessorAgent(self.ai_client)
```
**Responsabilidade**: Integra√ß√£o com servi√ßos de IA.

### **4. Site Configurations**
```python
self.site_configs: Dict[str, SiteConfig] = {}
```
**Responsabilidade**: Armazena configura√ß√µes de sites para scraping.

## Tratamento de Erros

### **Inicializa√ß√£o**
```python
try:
    self._init_ai_components()
except Exception as e:
    logger.warning(f"AI components initialization failed: {e}")
    # Application continues without AI features
```

### **Opera√ß√µes Cr√≠ticas**
```python
def create_scraping_task(self, site_name: str, priority: TaskPriority = TaskPriority.NORMAL) -> ScrapingTask:
    if not self._initialized:
        raise ApplicationNotInitializedError("Application must be initialized before creating tasks")
    
    if site_name not in self.site_configs:
        raise SiteConfigNotFoundError(f"Site configuration '{site_name}' not found")
```

## Configura√ß√£o

### **Configura√ß√µes de AI**
```python
ai_config = {
    'enable_openai': True,
    'enable_navigator': True,
    'enable_pdf_processor': True,
    'openai_api_key': os.getenv('OPENAI_API_KEY')
}
```

### **Configura√ß√µes do Motor**
```python
engine_config = {
    'max_workers': 3,
    'task_timeout': 300,
    'retry_attempts': 3
}
```

## Padr√µes de Design Utilizados

### **1. Singleton**
- Garante inst√¢ncia √∫nica da aplica√ß√£o
- Evita conflitos de estado

### **2. Facade**
- Fornece interface simplificada para sistema complexo
- Esconde complexidade interna

### **3. Dependency Injection**
- Componentes s√£o injetados na inicializa√ß√£o
- Facilita testes e manuten√ß√£o

## Exemplos de Uso

### **Inicializa√ß√£o B√°sica**
```python
from src.core.application import app

# Initialize application
app.initialize()
app.start()

# Check status
status = app.get_application_status()
print(f"App running: {status['running']}")
```

### **Cria√ß√£o de Tarefa**
```python
# Add site configuration
site_config = SiteConfig(name="example", base_url="https://example.com")
app.add_site_config(site_config)

# Create scraping task
task = app.create_scraping_task("example", TaskPriority.HIGH)
print(f"Task created: {task.task_id}")
```

### **Monitoramento**
```python
# Health check
health = app.health_check()
print(f"System health: {health['status']}")

# Metrics
metrics = app.get_metrics()
print(f"Success rate: {metrics['engine']['success_rate']:.2%}")
```

## Integra√ß√£o com Outros Componentes

### **CLI Interface**
```python
# cli_interface.py
from src.core.application import app

app.initialize()
app.start()
```

### **Interactive Mode**
```python
# interactive_mode.py
def __init__(self, app: WebScraperApplication):
    self.app = app
```

### **Site Modules**
```python
# base_site_module.py
def execute(self, app: WebScraperApplication) -> DownloadResult:
    # Access to all app resources
    scraper = app.create_scraper()
    ai_navigator = app.navigator
```

## Logs e Debugging

### **Logging Estruturado**
```python
logger.info("Application started", extra={
    "component": "application",
    "workers": max_workers,
    "ai_enabled": bool(self.ai_client)
})
```

### **Debug Information**
```python
def _debug_status(self) -> None:
    logger.debug(f"Site configs: {len(self.site_configs)}")
    logger.debug(f"Engine status: {self.engine.status if self.engine else 'None'}")
    logger.debug(f"AI components: {bool(self.ai_client)}")
```

---

**A classe WebScraperApplication √© fundamental para o funcionamento do sistema, fornecendo coordena√ß√£o centralizada e interface unificada para todos os componentes.**